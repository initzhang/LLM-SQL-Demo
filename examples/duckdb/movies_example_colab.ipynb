{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Queries in DuckDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through how to call LLMs directly as a UDF in a DuckDB database using [vLLM](https://github.com/vllm-project/vllm) as the inference engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the LLM Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose between OpenAI or vLLM with a quantized version of Llama-3 8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting vLLM engine...\n",
      "WARNING 04-25 14:57:57 config.py:169] gptq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 04-25 14:57:57 llm_engine.py:98] Initializing an LLM engine (v0.4.1) with config: model='TechxGenus/Meta-Llama-3-8B-Instruct-GPTQ', speculative_config=None, tokenizer='TechxGenus/Meta-Llama-3-8B-Instruct-GPTQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=gptq, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-25 14:57:58 utils.py:608] Found nccl from library /home/ray/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 04-25 14:57:58 selector.py:65] Cannot use FlashAttention backend for Volta and Turing GPUs.\n",
      "INFO 04-25 14:57:58 selector.py:33] Using XFormers backend.\n",
      "INFO 04-25 14:58:00 weight_utils.py:193] Using model weights format ['*.safetensors']\n",
      "INFO 04-25 14:58:02 model_runner.py:173] Loading model weights took 5.3472 GB\n",
      "INFO 04-25 14:58:08 gpu_executor.py:119] # GPU blocks: 2602, # CPU blocks: 2048\n",
      "INFO 04-25 14:58:10 model_runner.py:976] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 04-25 14:58:10 model_runner.py:980] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 04-25 14:58:22 model_runner.py:1057] Graph capturing finished in 12 secs.\n",
      "INFO 04-25 14:58:22 block_manager_v1.py:235] Automatic prefix caching is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the below code to initialize llmsql with OpenAI\n",
    "# import llmsql\n",
    "# from llmsql.llm.openai import OpenAI\n",
    "\n",
    "\n",
    "# llmsql.init(OpenAI(base_url=\"https://api.openai.com/v1\", api_key=\"<INSERT_OPENAI_KEY>\"))\n",
    "\n",
    "\n",
    "# Uncomment the below code to initialize llmsql with vLLM\n",
    "\n",
    "import llmsql\n",
    "from llmsql.llm.vllm import vLLM\n",
    "from vllm import EngineArgs\n",
    "args = EngineArgs(model=\"TechxGenus/Meta-Llama-3-8B-Instruct-GPTQ\")\n",
    "\n",
    "llmsql.init(vLLM(engine_args=args))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the movies dataset as a DuckDB table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x75b4c9e173f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure you import duckdb from llmsql\n",
    "from llmsql.duckdb import duckdb\n",
    "\n",
    "# Create a table from the movies dataset\n",
    "conn = duckdb.connect(database=':memory:', read_only=False)\n",
    "conn.execute(\"CREATE TABLE movies AS SELECT * FROM read_csv('../movies_small.csv')\")\n",
    "conn.execute(\"CREATE TABLE movies_limit as SELECT * FROM movies WHERE review_content IS NOT NULL LIMIT 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────┐\n",
      "│     name     │\n",
      "│   varchar    │\n",
      "├──────────────┤\n",
      "│ movies       │\n",
      "│ movies_limit │\n",
      "└──────────────┘\n",
      "\n",
      "┌──────────────────────┬─────────────┬─────────┬─────────┬─────────┬─────────┐\n",
      "│     column_name      │ column_type │  null   │   key   │ default │  extra  │\n",
      "│       varchar        │   varchar   │ varchar │ varchar │ varchar │ varchar │\n",
      "├──────────────────────┼─────────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│ rotten_tomatoes_link │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ review_content       │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ movie_title          │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ movie_info           │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ id                   │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "└──────────────────────┴─────────────┴─────────┴─────────┴─────────┴─────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the table and fields in the table\n",
    "\n",
    "print(conn.sql(\"SHOW TABLES\"))\n",
    "\n",
    "print(conn.sql(\"DESCRIBE movies_limit\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run sample LLM Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMs in Projection Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d48740903349dc9bb65a8dd4f89ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = (\n",
    "    \"SELECT review_content, LLM('Given a movie review as {review_content}, classify the review as either POSITIVE, NEGATIVE, or NEUTRAL.\" \n",
    "    \"Respond with just the category and no other text.', review_content) FROM movies_limit\")\n",
    "query_result = conn.execute(query).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie review: It's a series of routines within a routine formula, and the result is as tedious as it sounds.\n",
      "Sentiment: NEGATIVE\n",
      "\n",
      "Movie review: A vulgar exercise of terror that, despite its defects, manages to stand out from its delectable predecessors. [Full Review in Spanish]\n",
      "Sentiment: POSITIVE\n",
      "\n",
      "Movie review: After the Thin Man hasn't quite the spontaneity and charm of the original, but it's good mystery-comedy, the dialogue bright, the handling expert, and the principals as ingratiating as ever.\n",
      "Sentiment: POSITIVE\n",
      "\n",
      "Movie review: You never really get angry at it. You just want to shake it up because the elements for a first-class comedy thriller are all there. It's simply .that everything is always ten per cent off.\n",
      "Sentiment: NEUTRAL\n",
      "\n",
      "Movie review: An excellent film.\n",
      "Sentiment: POSITIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print first 5 results\n",
    "for result in query_result[:5]:\n",
    "    print(f\"Movie review: {result[0]}\")\n",
    "    print(f\"Sentiment: {result[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac54e6abeae44b6f8e58e887a8633da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = (\n",
    "    \"SELECT LLM('Given {movie_title}, {movie_info} and a movie review as {review_content}, extract all character names that are mentioned.\"\n",
    "    \"Respond with just the character names and no other text. If there are no characters, respond with just None', movie_title, movie_info, review_content) FROM movies_limit\")\n",
    "query_result = conn.execute(query).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character names: None\n",
      "Character names: None\n",
      "Character names: Nick Charles, Nora, Selma, Robert, David Graham\n",
      "Character names: Gene Wilder, Jill Clayburgh, Richard Pryor\n",
      "Character names: Dana Andrews, Lee J. Cobb, Henry Harvey\n"
     ]
    }
   ],
   "source": [
    "for result in query_result[:5]:\n",
    "    print(f\"Character names: {result[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the LLM query as filters, possibly in combination with projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813f9ef2bd484833961f2059d8322dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_query = (\n",
    "    \"SELECT movie_title FROM movies_limit WHERE \"\n",
    "    \"LLM('Given a movie review as {review_content}, classify the review as either POSITIVE, NEGATIVE, or NEUTRAL. \" \n",
    "    \"Respond with just the category and no other text.', review_content) == 'POSITIVE'\")\n",
    "query_result = conn.execute(filter_query).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amityville: The Awakening\n",
      "After the Thin Man\n",
      "Boomerang!\n",
      "American Gun\n",
      "White Fang\n"
     ]
    }
   ],
   "source": [
    "# Print first 5 results\n",
    "for result in zip(query_result[:5]):\n",
    "    print(f\"{result[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05fb1b954194831a3abcf1b82def62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = (\n",
    "    \"SELECT movie_title, LLM('Given {movie_title} and {movie_info}, determine if this movie is suitable for kids.', movie_title, movie_info) \"\n",
    "    \"FROM movies_limit WHERE \"\n",
    "    \"LLM('Given a movie review as {review_content}, classify the review as either POSITIVE, NEGATIVE, or NEUTRAL.\" \n",
    "    \"Respond with just the category and no other text.', review_content) == 'POSITIVE'\"\n",
    ")\n",
    "query_result = conn.execute(query).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie title: Amityville: The Awakening\n",
      "Suitable for kids: No, this movie is not suitable for kids.\n",
      "\n",
      "Movie title: After the Thin Man\n",
      "Suitable for kids: No\n",
      "\n",
      "Movie title: Silver Streak\n",
      "Suitable for kids: Not suitable for kids.\n",
      "\n",
      "Movie title: Boomerang!\n",
      "Suitable for kids: No\n",
      "\n",
      "Movie title: American Gun\n",
      "Suitable for kids: Based on the movie title and information, I would say the movie is NOT suitable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print first 5 results\n",
    "for result in query_result[:5]:\n",
    "    print(f\"Movie title: {result[0]}\")\n",
    "    print(f\"Suitable for kids: {result[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM queries can also be used in aggregates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc116f83ea0f4e28ac17c75543da7617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = (\n",
    "    \"SELECT movie_title, \" \n",
    "        \"AVG(CAST(LLM(\"\n",
    "            \"'Given a movie review as {review_content}, score the movie either as 1, 2, 3, with 3 as the highest. Return just the score and nothing else.', movie_title, movie_info) \"\n",
    "        \"AS integer)) \"\n",
    "    \"FROM movies_limit GROUP BY movie_title \"\n",
    ")\n",
    "query_result = conn.execute(query).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie title: Amityville: The Awakening\n",
      "Average review score: 2.3333333333333335\n",
      "\n",
      "Movie title: Silent Night, Deadly Night\n",
      "Average review score: 2.0\n",
      "\n",
      "Movie title: Hoodlum\n",
      "Average review score: 2.0\n",
      "\n",
      "Movie title: American Gun\n",
      "Average review score: 2.0\n",
      "\n",
      "Movie title: Armstrong\n",
      "Average review score: 2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print first 5 results\n",
    "for result in query_result[:5]:\n",
    "    print(f\"Movie title: {result[0]}\")\n",
    "    print(f\"Average review score: {result[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "query = \"SELECT movie_title from movies_limit\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
