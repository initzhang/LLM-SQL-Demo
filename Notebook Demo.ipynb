{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e0d944e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: Error importing numpy: you should not try to import numpy from\n        its source directory; please exit the numpy source tree, and relaunch\n        your python interpreter from there.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/asimbiswal/Desktop/Cal/RISELab/LLM-SQL-Demo/Notebook Demo.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/asimbiswal/Desktop/Cal/RISELab/LLM-SQL-Demo/Notebook%20Demo.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# import openai\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/asimbiswal/Desktop/Cal/RISELab/LLM-SQL-Demo/Notebook%20Demo.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/asimbiswal/Desktop/Cal/RISELab/LLM-SQL-Demo/Notebook%20Demo.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m List\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/asimbiswal/Desktop/Cal/RISELab/LLM-SQL-Demo/Notebook%20Demo.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mconcurrent\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfutures\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Cal/RISELab/LLM-SQL-Demo/llmsqldemo/lib/python3.10/site-packages/pandas/__init__.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m         _missing_dependencies\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m_dependency\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m_e\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m _missing_dependencies:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     20\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to import required dependencies:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(_missing_dependencies)\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m \u001b[39mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[39m# numpy compat\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: Error importing numpy: you should not try to import numpy from\n        its source directory; please exit the numpy source tree, and relaunch\n        your python interpreter from there."
     ]
    }
   ],
   "source": [
    "# import openai\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b89683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_key():\n",
    "    openai.api_type = \"azure\"\n",
    "    openai.api_base = \"https://shu-audrey-joey.openai.azure.com/\"\n",
    "    openai.api_version = \"2023-07-01-preview\"\n",
    "    openai.api_key = \"54a4a22814764408b727b9791ed2a544\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16351f71",
   "metadata": {},
   "source": [
    "# Example of DuckDB UDF and List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5371ce26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────────────────────────┐\n",
       "│ my_func(main.list_value(32, 42)) │\n",
       "│             varchar              │\n",
       "├──────────────────────────────────┤\n",
       "│ [32, 42]                         │\n",
       "└──────────────────────────────────┘"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "from typing import List \n",
    "\n",
    "def my_function(x: List) -> str:\n",
    "    return x\n",
    "\n",
    "duckdb.create_function(\"my_func\", my_function)\n",
    "sample_list = [32, 42]\n",
    "duckdb.sql(f\"SELECT my_func({sample_list})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dfde3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# Establish a connection to the database (this creates an in-memory database if no path is provided)\n",
    "conn = duckdb.connect(database=':memory:', read_only=False)\n",
    "\n",
    "# You would typically load your data here or ensure that your database contains the necessary tables.\n",
    "# For demonstration, I'll create a sample table and insert some data into it.\n",
    "conn.execute(\"CREATE TABLE example_table (example_column INT)\")\n",
    "conn.execute(\"INSERT INTO example_table VALUES (1), (2), (3), (4), (5)\")\n",
    "\n",
    "# Now, let's convert a column from the table into a Python list\n",
    "query_result = conn.execute(\"SELECT example_column FROM example_table\").fetchall()\n",
    "\n",
    "# Convert the result into a list (note that fetchall returns a list of tuples, so we extract the first element)\n",
    "example_list = [row[0] for row in query_result]\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Now you have your column data in a Python list\n",
    "print(example_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadcfb36",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19c38f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   album_id                                  title  artist_id\n",
      "0         1  For Those About To Rock We Salute You          1\n",
      "1         2                      Balls to the Wall          2\n",
      "2         3                      Restless and Wild          2\n",
      "3         4                      Let There Be Rock          1\n",
      "4         5                               Big Ones          3\n"
     ]
    }
   ],
   "source": [
    "# Path to your DuckDB database file\n",
    "duckdb_db_path = 'chinook.duckdb'\n",
    "conn = duckdb.connect(duckdb_db_path)\n",
    "query = \"SELECT * FROM Albums;\"\n",
    "df = conn.execute(query).df()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5114e381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   artist_id               name\n",
      "0          1              AC/DC\n",
      "1          2             Accept\n",
      "2          3          Aerosmith\n",
      "3          4  Alanis Morissette\n",
      "4          5    Alice In Chains\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM Artists;\"\n",
    "df = conn.execute(query).df()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a8b94e",
   "metadata": {},
   "source": [
    "# Read Movies Dataset (small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f32119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"movies_small.csv\")\n",
    "duckdb_df = duckdb.from_df(df, conn)\n",
    "print(duckdb_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c614583",
   "metadata": {},
   "source": [
    "# UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f576d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(query: str, context: List[str]):\n",
    "    \"\"\"\n",
    "    query: e.x. find the artist mentioned in the {review}\n",
    "    context: e.x. List[review]\n",
    "    \"\"\"\n",
    "    \n",
    "#     set_model_key()\n",
    "#     llm_chain = llm_dict[query]\n",
    "#     output = llm_chain.batch(context)\n",
    "\n",
    "    def invoke_llm(query: str, context: str, fields: List[str]):\n",
    "        \"\"\"\n",
    "        query: e.x. find the artist mentioned in the {review}\n",
    "        context: e.x. review \n",
    "        \"\"\"\n",
    "        set_model_key()\n",
    "\n",
    "        # TODO UPDATE THIS SYSTEM PROMPT\n",
    "        response_format = \"\"\"\n",
    "            You are a data analysis assistant who will respond with the artist name mentioned on reviews inputted. Answer with only the name.\n",
    "            For instance:\n",
    "            - If the review is 'I love the songs by Taylor Swift.', the answer is 'Taylor Swift'.\n",
    "            - If the review is 'This album reminds me of the Beatles', the answer is 'the Beatles'.\n",
    "        \"\"\"\n",
    "        \n",
    "        num_fields = len(fields)\n",
    "        prompt = query\n",
    "\n",
    "        for i in range(num_fields):\n",
    "            field_val = context[i] if context[i] else \"None\"\n",
    "            if isinstance(field_val, list):\n",
    "                field_val = field_val[0]\n",
    "            prompt += fields[i] + \": \" + field_val + \"\\n\"\n",
    "        if len(prompt) > 16000:\n",
    "            prompt = query + \"N/A\"\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=DEPLOYMENT_NAME, # engine = \"deployment_name\".\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": response_format},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        output = response['choices'][0]['message']['content']\n",
    "        return output\n",
    "\n",
    "    \n",
    "    responses = []\n",
    "    # We can use a with statement to ensure threads are cleaned up promptly\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        # Start the load operations and mark each future with its URL\n",
    "        future_to_response = {executor.submit(invoke_llm, query, row): row for row in context}\n",
    "        for future in concurrent.futures.as_completed(future_to_response):\n",
    "            row = future_to_response[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "                responses.append(data)\n",
    "            except Exception as exc:\n",
    "                print('%r generated an exception: %s' % (row, exc))\n",
    "    \n",
    "    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9860a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {}\n",
    "fields = [\"movie_info\", \"review_type\"]\n",
    "types = [\"VARCHAR\", \"VARCHAR\"]\n",
    "for i in len(fields):\n",
    "    context[fields[i]] = types[i]\n",
    "duckdb.struct_type(context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
